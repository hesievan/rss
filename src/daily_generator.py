#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import logging
from datetime import datetime
from typing import List, Dict, Any
from collections import defaultdict

class DailyGenerator:
    """æ—¥æŠ¥ç”Ÿæˆæ¨¡å—"""
    
    def __init__(self):
        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def generate_daily_report(self, articles: List[Dict[str, Any]], 
                            max_items: int = 50) -> Dict[str, Any]:
        """ç”Ÿæˆæ—¥æŠ¥å†…å®¹"""
        if not articles:
            return self._generate_empty_report()
        
        # é™åˆ¶æ–‡ç« æ•°é‡
        articles = articles[:max_items]
        
        # æŒ‰æ¥æºåˆ†ç»„
        articles_by_source = self._group_by_source(articles)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            'title': self._generate_title(),
            'summary': self._generate_summary(articles),
            'sections': self._generate_sections(articles_by_source),
            'statistics': self._generate_statistics(articles),
            'generated_at': datetime.now().isoformat()
        }
        
        self.logger.info(f"ç”Ÿæˆæ—¥æŠ¥å®Œæˆï¼ŒåŒ…å« {len(articles)} ç¯‡æ–‡ç« ")
        return report
    
    def _generate_title(self) -> str:
        """ç”Ÿæˆæ—¥æŠ¥æ ‡é¢˜"""
        today = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
        return f"ğŸ“° ç§‘æŠ€æ—¥æŠ¥ - {today}"
    
    def _generate_summary(self, articles: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆæ—¥æŠ¥æ‘˜è¦"""
        total_articles = len(articles)
        sources = set(article['source'] for article in articles)
        
        summary = f"ä»Šæ—¥å…±ç­›é€‰å‡º {total_articles} ç¯‡é‡è¦èµ„è®¯ï¼Œ"
        summary += f"æ¥è‡ª {len(sources)} ä¸ªä¿¡æ¯æºã€‚"
        
        if total_articles > 0:
            # ç»Ÿè®¡çƒ­é—¨å…³é”®è¯
            keyword_stats = self._analyze_keywords(articles)
            if keyword_stats:
                top_keywords = list(keyword_stats.items())[:3]
                keyword_str = "ã€".join([f"{kw}({count})" for kw, count in top_keywords])
                summary += f" çƒ­é—¨è¯é¢˜ï¼š{keyword_str}ã€‚"
        
        return summary
    
    def _generate_sections(self, articles_by_source: Dict[str, List[Dict[str, Any]]]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ—¥æŠ¥ç« èŠ‚"""
        sections = []
        
        for source_name, articles in articles_by_source.items():
            section = {
                'title': f"ğŸ“Š {source_name}",
                'articles': []
            }
            
            for article in articles:
                article_item = {
                    'title': article['title'],
                    'link': article['link'],
                    'published': article['published'].strftime('%H:%M'),
                    'summary': self._truncate_summary(article.get('summary', ''), 100)
                }
                section['articles'].append(article_item)
            
            sections.append(section)
        
        return sections
    
    def _generate_statistics(self, articles: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        sources = defaultdict(int)
        hours = defaultdict(int)
        
        for article in articles:
            sources[article['source']] += 1
            hour = article['published'].hour
            hours[f"{hour:02d}:00"] += 1
        
        return {
            'total_articles': len(articles),
            'source_distribution': dict(sources),
            'hourly_distribution': dict(hours),
            'top_sources': sorted(sources.items(), key=lambda x: x[1], reverse=True)[:3]
        }
    
    def _group_by_source(self, articles: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """æŒ‰æ¥æºåˆ†ç»„æ–‡ç« """
        grouped = defaultdict(list)
        for article in articles:
            grouped[article['source']].append(article)
        return dict(grouped)
    
    def _analyze_keywords(self, articles: List[Dict[str, Any]]) -> Dict[str, int]:
        """åˆ†æå…³é”®è¯é¢‘ç‡"""
        keyword_count = defaultdict(int)
        
        # å¸¸è§ç§‘æŠ€å…³é”®è¯
        tech_keywords = [
            'AI', 'äººå·¥æ™ºèƒ½', 'æœºå™¨å­¦ä¹ ', 'ChatGPT', 'å¤§æ¨¡å‹', 'ç§‘æŠ€', 'åˆ›æ–°',
            'åˆ›ä¸š', 'æŠ•èµ„', 'èèµ„', 'IPO', 'ä¸Šå¸‚', 'æ”¶è´­', 'åˆå¹¶', 'è£å‘˜',
            'èŠ¯ç‰‡', 'åŠå¯¼ä½“', 'æ–°èƒ½æº', 'ç”µåŠ¨è½¦', 'å…ƒå®‡å®™', 'Web3', 'åŒºå—é“¾'
        ]
        
        for article in articles:
            title = article['title'].lower()
            summary = article.get('summary', '').lower()
            content = f"{title} {summary}"
            
            for keyword in tech_keywords:
                if keyword.lower() in content:
                    keyword_count[keyword] += 1
        
        return dict(sorted(keyword_count.items(), key=lambda x: x[1], reverse=True))
    
    def _truncate_summary(self, summary: str, max_length: int) -> str:
        """æˆªæ–­æ‘˜è¦"""
        if len(summary) <= max_length:
            return summary
        return summary[:max_length] + "..."
    
    def _generate_empty_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç©ºæŠ¥å‘Š"""
        return {
            'title': self._generate_title(),
            'summary': "ä»Šæ—¥æš‚æ— é‡è¦èµ„è®¯ã€‚",
            'sections': [],
            'statistics': {
                'total_articles': 0,
                'source_distribution': {},
                'hourly_distribution': {},
                'top_sources': []
            },
            'generated_at': datetime.now().isoformat()
        }
    
    def format_for_feishu(self, report: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–ä¸ºé£ä¹¦æ¶ˆæ¯æ ¼å¼"""
        content = f"# {report['title']}\n\n"
        content += f"## ğŸ“‹ ä»Šæ—¥æ‘˜è¦\n{report['summary']}\n\n"
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        stats = report['statistics']
        content += f"## ğŸ“Š æ•°æ®ç»Ÿè®¡\n"
        content += f"- æ€»æ–‡ç« æ•°ï¼š{stats['total_articles']} ç¯‡\n"
        if stats['top_sources']:
            content += f"- ä¸»è¦æ¥æºï¼š{', '.join([f'{source}({count})' for source, count in stats['top_sources']])}\n"
        content += "\n"
        
        # æ·»åŠ å„ç« èŠ‚å†…å®¹
        for section in report['sections']:
            content += f"## {section['title']}\n"
            for article in section['articles']:
                content += f"- **{article['title']}** [{article['published']}]\n"
                content += f"  {article['link']}\n"
                if article['summary']:
                    content += f"  > {article['summary']}\n"
                content += "\n"
        
        content += f"---\n*ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*"
        
        return content
    
    def format_for_markdown(self, report: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–ä¸º Markdown æ ¼å¼"""
        return self.format_for_feishu(report)
    
    def save_report(self, report: Dict[str, Any], filename: str = None) -> str:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        if not filename:
            today = datetime.now().strftime('%Y%m%d')
            filename = f"reports/daily_report_{today}.json"
        
        try:
            import os
            os.makedirs(os.path.dirname(filename), exist_ok=True)
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2, default=str)
            
            self.logger.info(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
            return filename
        except Exception as e:
            self.logger.error(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
            return ""

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    generator = DailyGenerator()
    
    # æ¨¡æ‹Ÿæ–‡ç« æ•°æ®
    test_articles = [
        {
            'title': 'OpenAI å‘å¸ƒ GPT-5 æ¨¡å‹',
            'link': 'https://example.com/1',
            'published': datetime.now(),
            'summary': 'OpenAI å‘å¸ƒäº†æœ€æ–°çš„ GPT-5 æ¨¡å‹ï¼Œæ€§èƒ½å¤§å¹…æå‡',
            'source': '36æ°ª'
        },
        {
            'title': 'ç‰¹æ–¯æ‹‰å‘å¸ƒæ–°æ¬¾ç”µåŠ¨è½¦',
            'link': 'https://example.com/2',
            'published': datetime.now(),
            'summary': 'ç‰¹æ–¯æ‹‰å‘å¸ƒäº†å…¨æ–°çš„ç”µåŠ¨è½¦äº§å“çº¿',
            'source': 'è™å—…ç½‘'
        }
    ]
    
    # ç”ŸæˆæŠ¥å‘Š
    report = generator.generate_daily_report(test_articles)
    
    # æ ¼å¼åŒ–ä¸ºé£ä¹¦æ¶ˆæ¯
    feishu_content = generator.format_for_feishu(report)
    print("é£ä¹¦æ¶ˆæ¯æ ¼å¼:")
    print(feishu_content)
    
    # ä¿å­˜æŠ¥å‘Š
    generator.save_report(report) 